Este experimento fora apresentado ao Alvaro com o intuito de mostrar a curva de crescimento da medida ModeRecall em função da quantidade
de exemplos utilizada.

Calcular BEST? s/N? s

Escolha a chave pra ordenara saida BEST: ['nome', 'ModeRecall', 'Attempted', 'ModePrecision', 'Precision', 'TotalWithMode', 'Recall', 'Total']: ModeRecall


MODERECALL	-----------------------
{'nome': u'Alvaro.best', 'ModeRecall': 100.0, 'Attempted': 1230.0, 'ModePrecision': 100.0, 'Precision': 52.5, 'TotalWithMode': 1230.0, 'Total': 1696.0}
{'nome': 'alvaro-3-AUTO-Exemplos:8.best', 'ModeRecall': 24.8, 'Attempted': 1229.0, 'ModePrecision': 24.82, 'Precision': 28.48, 'TotalWithMode': 1230.0, 'Total': 1696.0}
{'nome': 'alvaro-3-AUTO-Exemplos:4.best', 'ModeRecall': 24.07, 'Attempted': 1229.0, 'ModePrecision': 24.08, 'Precision': 28.26, 'TotalWithMode': 1230.0, 'Total': 1696.0}
{'nome': 'alvaro-3-AUTO-Exemplos:3.best', 'ModeRecall': 23.9, 'Attempted': 1229.0, 'ModePrecision': 23.92, 'Precision': 28.18, 'TotalWithMode': 1230.0, 'Total': 1696.0}
{'nome': 'alvaro-3-AUTO-Exemplos:2.best', 'ModeRecall': 23.58, 'Attempted': 1229.0, 'ModePrecision': 23.6, 'Precision': 28.25, 'TotalWithMode': 1230.0, 'Total': 1696.0}
{'nome': 'alvaro-3-AUTO-Exemplos:1.best', 'ModeRecall': 23.09, 'Attempted': 1229.0, 'ModePrecision': 23.11, 'Precision': 28.16, 'TotalWithMode': 1230.0, 'Total': 1696.0}
{'nome': u'UNT.best', 'ModeRecall': 20.73, 'Attempted': 1230.0, 'ModePrecision': 20.73, 'Precision': 12.77, 'TotalWithMode': 1230.0, 'Total': 1696.0}
{'nome': u'KU.best', 'ModeRecall': 20.65, 'Attempted': 1230.0, 'ModePrecision': 20.65, 'Precision': 12.9, 'TotalWithMode': 1230.0, 'Total': 1696.0}
{'nome': u'MELB.best', 'ModeRecall': 20.41, 'Attempted': 1230.0, 'ModePrecision': 20.41, 'Precision': 12.68, 'TotalWithMode': 1230.0, 'Total': 1696.0}
{'nome': u'IRST2.best', 'ModeRecall': 20.33, 'Attempted': 1230.0, 'ModePrecision': 20.33, 'Precision': 6.95, 'TotalWithMode': 1230.0, 'Total': 1696.0}
{'nome': u'HIT.best', 'ModeRecall': 18.86, 'Attempted': 1230.0, 'ModePrecision': 18.86, 'Precision': 11.35, 'TotalWithMode': 1230.0, 'Total': 1696.0}
{'nome': u'usyd.best', 'ModeRecall': 17.64, 'Attempted': 1191.0, 'ModePrecision': 18.22, 'Precision': 11.23, 'TotalWithMode': 1230.0, 'Total': 1696.0}
{'nome': u'IRST1.best', 'ModeRecall': 13.09, 'Attempted': 1230.0, 'ModePrecision': 13.09, 'Precision': 8.06, 'TotalWithMode': 1230.0, 'Total': 1696.0}
{'nome': u'TOR.best', 'ModeRecall': 4.72, 'Attempted': 1230.0, 'ModePrecision': 4.72, 'Precision': 2.98, 'TotalWithMode': 1230.0, 'Total': 1696.0}
Calcular Out-of-Ten? s/N? s

Escolha a chave pra ordenara saida OOT: ['nome', 'Attempted', 'Precision', 'TotalWithMode', 'Recall', 'Total']: Recall


RECALL	-----------------------
{'nome': u'Alvaro.oot', 'Attempted': 1230.0, 'Precision': 100.0, 'TotalWithMode': 1230.0, 'Recall': 100.0, 'Total': 1696.0}
{'nome': u'UNT.oot', 'Attempted': 1230.0, 'Precision': 66.26, 'TotalWithMode': 1230.0, 'Recall': 66.26, 'Total': 1696.0}
{'nome': u'KU.oot', 'Attempted': 1230.0, 'Precision': 61.3, 'TotalWithMode': 1230.0, 'Recall': 61.3, 'Total': 1696.0}
{'nome': u'IRST2.oot', 'Attempted': 1230.0, 'Precision': 58.54, 'TotalWithMode': 1230.0, 'Recall': 58.54, 'Total': 1696.0}
{'nome': u'IRST1.oot', 'Attempted': 1230.0, 'Precision': 55.28, 'TotalWithMode': 1230.0, 'Recall': 55.28, 'Total': 1696.0}
{'nome': 'alvaro-3-AUTO-Exemplos:2.oot', 'Attempted': 1229.0, 'Precision': 52.4, 'TotalWithMode': 1230.0, 'Recall': 52.36, 'Total': 1696.0}
{'nome': 'alvaro-3-AUTO-Exemplos:4.oot', 'Attempted': 1229.0, 'Precision': 52.4, 'TotalWithMode': 1230.0, 'Recall': 52.36, 'Total': 1696.0}
{'nome': 'alvaro-3-AUTO-Exemplos:1.oot', 'Attempted': 1229.0, 'Precision': 52.32, 'TotalWithMode': 1230.0, 'Recall': 52.28, 'Total': 1696.0}
{'nome': 'alvaro-3-AUTO-Exemplos:3.oot', 'Attempted': 1229.0, 'Precision': 52.24, 'TotalWithMode': 1230.0, 'Recall': 52.2, 'Total': 1696.0}
{'nome': 'alvaro-3-AUTO-Exemplos:8.oot', 'Attempted': 1229.0, 'Precision': 52.16, 'TotalWithMode': 1230.0, 'Recall': 52.11, 'Total': 1696.0}
{'nome': u'HIT.oot', 'Attempted': 1230.0, 'Precision': 46.91, 'TotalWithMode': 1230.0, 'Recall': 46.91, 'Total': 1696.0}
{'nome': u'SWAG2.oot', 'Attempted': 1128.0, 'Precision': 50.18, 'TotalWithMode': 1230.0, 'Recall': 46.02, 'Total': 1696.0}
{'nome': u'SWAG.oot', 'Attempted': 1137.0, 'Precision': 47.41, 'TotalWithMode': 1230.0, 'Recall': 43.82, 'Total': 1696.0}
{'nome': u'usyd.oot', 'Attempted': 1191.0, 'Precision': 43.66, 'TotalWithMode': 1230.0, 'Recall': 42.28, 'Total': 1696.0}
{'nome': 'alvaro-2-AUTO-Exemplos:8.oot', 'Attempted': 1229.0, 'Precision': 42.07, 'TotalWithMode': 1230.0, 'Recall': 42.03, 'Total': 1696.0}
{'nome': 'alvaro-2-AUTO-Exemplos:2.oot', 'Attempted': 1229.0, 'Precision': 41.99, 'TotalWithMode': 1230.0, 'Recall': 41.95, 'Total': 1696.0}
{'nome': 'alvaro-2-AUTO-Exemplos:1.oot', 'Attempted': 1229.0, 'Precision': 41.5, 'TotalWithMode': 1230.0, 'Recall': 41.46, 'Total': 1696.0}
{'nome': 'alvaro-2-AUTO-Exemplos:3.oot', 'Attempted': 1229.0, 'Precision': 41.17, 'TotalWithMode': 1230.0, 'Recall': 41.14, 'Total': 1696.0}
{'nome': 'alvaro-2-AUTO-Exemplos:4.oot', 'Attempted': 1229.0, 'Precision': 41.01, 'TotalWithMode': 1230.0, 'Recall': 40.98, 'Total': 1696.0}
{'nome': 'alvaro-1-AUTO-Exemplos:8.oot', 'Attempted': 1229.0, 'Precision': 24.82, 'TotalWithMode': 1230.0, 'Recall': 24.8, 'Total': 1696.0}
{'nome': 'alvaro-1-AUTO-Exemplos:4.oot', 'Attempted': 1229.0, 'Precision': 24.08, 'TotalWithMode': 1230.0, 'Recall': 24.07, 'Total': 1696.0}
{'nome': 'alvaro-1-AUTO-Exemplos:3.oot', 'Attempted': 1229.0, 'Precision': 23.92, 'TotalWithMode': 1230.0, 'Recall': 23.9, 'Total': 1696.0}
{'nome': 'alvaro-1-AUTO-Exemplos:2.oot', 'Attempted': 1229.0, 'Precision': 23.6, 'TotalWithMode': 1230.0, 'Recall': 23.58, 'Total': 1696.0}
{'nome': 'alvaro-1-AUTO-Exemplos:1.oot', 'Attempted': 1229.0, 'Precision': 23.11, 'TotalWithMode': 1230.0, 'Recall': 23.09, 'Total': 1696.0}
{'nome': u'TOR.oot', 'Attempted': 1230.0, 'Precision': 14.63, 'TotalWithMode': 1230.0, 'Recall': 14.63, 'Total': 1696.0}
